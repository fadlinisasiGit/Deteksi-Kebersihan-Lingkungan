# -*- coding: utf-8 -*-
"""Pendeteksi_Kebersihan_Lingkungan4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C3JygsFpHUB49tNTADRRse-9qqMZ39h4
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# mengecek versi Tensorflow di Colab
import tensorflow as tf
print(tf.__version__)

!pip install opendatasets

# install paket kaggle
!pip install -q kaggle

# Upload file kaggle.json dari Create New API Token Akun Kaggle
from google.colab import files
files.upload()

import opendatasets as od
dataset_url= 'https://www.kaggle.com/mfadliramadhan/cleandirtygarbage'
od.download('https://www.kaggle.com/mfadliramadhan/cleandirtygarbage')

# melakukan ekstraksi pada file zip
import zipfile,os

 
base_dir = '/content/cleandirtygarbage/garbage'
train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')

os.listdir('/content/cleandirtygarbage/garbage/train')
os.listdir('/content/cleandirtygarbage/garbage/test')

# Total seluruh data
train_clean = len(os.listdir('/content/cleandirtygarbage/garbage/train/clean'))
train_dirty = len(os.listdir('/content/cleandirtygarbage/garbage/train/dirty'))
test_clean = len(os.listdir('/content/cleandirtygarbage/garbage/test/clean'))
test_dirty = len(os.listdir('/content/cleandirtygarbage/garbage/test/dirty'))

print("count data: ")
print("train clean: " + str(train_clean))
print("train dirty: " + str(train_dirty))
print("train clean: " + str(test_clean))
print("test dirty: " + str(test_dirty))
print("total: "+ str(train_clean+train_dirty+test_clean+test_dirty))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2)

test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2)

train_generator = train_datagen.flow_from_directory(
        train_dir,  # direktori data latih
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4,
        # karena kita merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'
        class_mode='binary',
        subset = 'training')

test_generator = test_datagen.flow_from_directory(
        test_dir, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4, # karena kita merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'
        class_mode='binary',
        subset = 'validation')

print(train_generator.class_indices)

# membangun arsitektur sebuah CNN
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.summary()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>=0.98 and logs.get('val_accuracy')>=0.98):
      print("\nTraining Model Stopped! Accuracy Model is very good!")
      self.model.stop_training = True
callbacks = myCallback()

# Optimizer dengan learning rate
from tensorflow.keras.optimizers import Adam

adam = Adam(lr=0.0001)

model.compile(loss = 'binary_crossentropy',
              optimizer = adam,
              metrics = ['accuracy'])

history = model.fit(
      train_generator,  
      epochs=200, 
      steps_per_epoch=25,
      validation_data=test_generator,
      validation_steps=5, 
      verbose=2,
      callbacks=[callbacks])

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# Commented out IPython magic to ensure Python compatibility.
# melihat hasil dari model yang telah Anda buat pada Notebook. 
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes==0:
    print('bersih')
  else:
    print('kotor')

# METRIK EVALUSASI
# MEMBUAT PLOT AKURASI dan LOSS TRAINING DAN VALIDATION
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.figure()
plt.show()

# Menyimpan Model ke Format TF-Lite
# Mengkonversi Model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Menyimpan Model
with open('model_deteksi.tflite', 'wb') as f:
  f.write(tflite_model)

# SAVE MODEL TO JSON
from keras.models import model_from_json

# serialize model to JSON
model_json = model.to_json()

with open("model_deteksi.json", "w") as json_file:
    json_file.write(model_json)

# save weights to HDF5
model.save_weights("model_weight_deteksi.h5")
print("Model saved")

# Save Model to HDF5
model.save("model_deteksi.h5")